{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The code below loads the data from Hugging Face, or from the local cache if it has been downloaded before. Once it is loaded, it is an ordinary Python dictionary with the structure of the following example:\n",
    "\n",
    "> {'Source': '‡Ωê‡Ω¥‡Ωñ‡ºã‡Ωî‡Ω¶‡ºã‡Ω¢‡æü‡ΩÇ‡ºã‡Ωè‡Ω¥‡ºã‡Ωë‡Ω∫‡ºã‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã‡Ω¶‡æ§‡æ±‡Ωë‡ºç‡ºç',\n",
    " 'Target': 'The aspirant should move in such a way at all times.',\n",
    " 'File_Name': 'TM2382',\n",
    " 'Machine Aligned': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "texts = load_dataset('openpecha/cleaned_MT_v1.0.2', split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toward a Cleaner Translation Dataset\n",
    "\n",
    "While performing topic modeling on the translation dataset 'openpecha/cleaned_MT_v1.0.2' it was discovered that some elements ('sentence pairs') of the dataset may present problems for model training. There are 3 primary issues:\n",
    "\n",
    "1. Some elements have Tibetan text in the target output. This can lead to poor results from models trained on the dataset and is undesirable. \n",
    "2. Some elements contain emojis in either the source or target text.\n",
    "3. Some elements appear to consist entirely of numerals and punctuation. \n",
    "\n",
    "Samples were extracted programmatically for this analysis. Entries in the dataset as downloaded from Hugging Face are Python dictionary with the structure of the following example:\n",
    "\n",
    "> {'Source': '‡Ωê‡Ω¥‡Ωñ‡ºã‡Ωî‡Ω¶‡ºã‡Ω¢‡æü‡ΩÇ‡ºã‡Ωè‡Ω¥‡ºã‡Ωë‡Ω∫‡ºã‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã‡Ω¶‡æ§‡æ±‡Ωë‡ºç‡ºç',\n",
    " 'Target': 'The aspirant should move in such a way at all times.',\n",
    " 'File_Name': 'TM2382',\n",
    " 'Machine Aligned': True}\n",
    "\n",
    "Notably, the dictionaries lack an 'id' entry. This makes reproducibility less reliable. It is recommended that 'id' numbers be added for future versions.\n",
    "\n",
    "## Tibetan in the Target Text\n",
    "\n",
    "Tibetan text is in the Unicode block (U+0F00-0FFF). We can find elements of the dataset that have Tibetan in the target output by searching for dictionaries where characters in the 'Target' entry fall within that Unicode range, record the index of that dictionary (i.e. texts[0], texts[785], etc.) and then pull those dictionaries from the over all dataset.\n",
    "\n",
    "Sentence pairs that include Tibetan text in the target ouput were extracted using the following python code:\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "texts = load_dataset('openpecha/cleaned_MT_v1.0.2', split=\"train\")\n",
    "\n",
    "tibetan_range = range(0x0F00, 0x0FFF + 1)\n",
    "locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for char in texts[i]['Target']:\n",
    "            if ord(char) in tibetan_range:\n",
    "                locs.append(i)\n",
    "                break\n",
    "```\n",
    "\n",
    "This was repeated with the test set as well.\n",
    "\n",
    "### Train Split\n",
    "\n",
    "TThere are 2423 such elements in the train split. These elements in the train split fall roughly into three categories.\n",
    "\n",
    "1. Some have Tibetan characters occur as part of an English sentence, largely as examples from language learning textbooks like so:\n",
    "\n",
    ">*'Further, when an action being done is one of ‚Äúno apparent agentother‚Äù, for example in ‡Ωõ‡ºã‡Ωò‡ΩÅ‡Ωì‡ºã‡ΩÇ‡æ±‡Ω≤‡ºã‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ω£‡Ωº‡ºã‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ω¢‡Ωº‡ºç ‚Äúthe potter‚Äôs wheel turning‚Äù, initially there is ‡Ω¶‡æê‡Ωº‡Ω¢‡ºã‡Ωñ‡æ±‡Ω∫‡Ωë‡ºã‡ΩÇ‡Ωû‡Ωì‡ºã a turner and an other from it but once the wheel ‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã‡Ωî‡Ω†‡Ω≤‡ºã is turning, that is, when it is just turning of itself without turner who is other, given that the situation has a non-separate action and agent, it is not expressed with ‚Äú‡Ωñ‡Ω¶‡æê‡Ωº‡Ω¢‡ºã‚Äù but expressed with ‚Äú‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‚Äù. Further, when agent-other is not actually apparent, for example in ‡Ω¶‡æê‡æ±‡Ω∫‡Ω¶‡ºã‡Ωñ‡Ω¥‡ºã‡Ωû‡Ω≤‡ΩÇ‡ºã‡ΩÇ‡Ω≤‡ºã‡Ωò‡Ωë‡Ω¥‡Ωì‡ºã‡Ωë‡Ω¥‡ºã‡Ω£‡æï‡ΩÇ‡Ω¶‡ºã‡Ω§‡Ω≤‡ΩÇ‡ºã‡Ω¢‡ΩÑ‡ºã‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã‡ΩÇ‡æ±‡Ω≤‡Ω¶‡ºã‡ΩÇ‡Ω¶‡Ω∫‡Ω¢‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡æ±‡Ω¥‡Ω¢‡ºã‡Ωî‡ºã ‚Äúright before a person iron turned to gold by itself‚Äù the merit of that person is indeed the agent-other nonetheless that merit is not actually apparent and given that change occurs by the iron itself acting38 this is not expressed as iron turned into gold with ‚Äú‡Ωñ‡Ω¶‡æí‡æ±‡Ω¥‡Ω¢‡ºã‚Äù but with ‚Äú‡ΩÇ‡æ±‡Ω¥‡Ω¢‡ºã‚Äù. Moreover, when this is analysed very closely, from the stance of the self-character of each thing involved, ‚Äúsomething of itself to itself‚Äù transgresses action-agent but generally, from the stance of a rough take on it, merely in convention there is no transgression.'*\n",
    "\n",
    "2. Some seem to be mistakes in the machine alignment of the dataset like so:\n",
    "\n",
    ">*'‡Ωñ‡Ω¶‡ºã‡Ω†‡Ωë‡Ω≤‡ºã ‡Ωò‡Ω¶‡ºã‡Ωö‡Ω≤‡ΩÇ‡ºã‡ΩÇ‡Ω¶‡Ω£‡ºã‡Ω£‡Ω¶‡ºã‡ΩÇ ‡ΩÑ‡Ω¶‡ºã‡Ωî‡ºã ‡Ωò‡Ω¶‡ºã‡ΩÄ‡æ±‡Ω≤‡ºã‡Ωì‡ΩÑ‡ºã ‡Ωì‡Ω¶‡ºã‡ΩÄ‡æ±‡ΩÑ‡ºã‡Ω§‡Ω≤‡Ωì‡ºã ‡ºã ‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ωë‡ΩÄ‡Ω†‡ºã‡Ωñ‡Ω¢‡ºã ‡ΩÑ‡ºã‡Ωñ‡Ω¶‡ºã‡Ωö‡Ω≤‡ΩÇ‡ºã‡ΩÇ‡Ω¶‡Ω£‡ºã‡ΩÇ‡æ±‡Ω≤‡ºã‡Ωö‡Ω≤‡ΩÇ‡ºã ‡ΩÑ‡Ω¶‡ºã‡Ωè‡Ω∫‡ºã‡Ωñ‡Ω§‡Ωë‡ºã‡Ωì‡ºç ‡Ωá‡Ω≤‡ºã ‡Ωë‡ºã ‡ºç ‡ΩÖ‡Ω≤‡ºã ‡Ω∫‡ºã‡Ωá‡Ω≤‡ºã ‡Ω¢‡ºã ‡ºã‡Ωò‡Ω≤‡ºã ‡ΩÇ‡ºã‡ΩÖ‡Ω∫‡Ω¶‡ºã ‡ºã ‡Ωñ‡ºã‡Ω£‡ºã‡ΩÜ‡Ωº‡Ω¶‡ºã‡Ωë‡ΩÑ‡ºã‡ΩÜ‡Ωº‡Ω¶‡ºã‡ΩÖ‡Ωì‡ºã‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã ‡Ω≤‡ºã‡Ωâ‡Ω≤‡Ωë‡ºã‡Ωñ ‡ΩÑ‡ºã‡Ωñ‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡ΩÇ‡æ±‡Ω≤‡ºã‡ΩÅ‡æ±‡Ωë‡ºã ‡Ωî‡Ω¢‡ºã‡Ωì‡Ω≤‡ºã‡Ωò‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡Ωè‡Ω∫‡ºç ‡ΩÅ‡æ±‡Ωë‡ºã‡Ωî‡Ω¢‡ºã‡Ω†‡Ωõ‡Ω≤‡Ωì‡ºã‡Ωì‡ºã‡Ωì‡Ω≤‡ºã ‡Ω∫‡Ω¶‡ºã ‡ºã‡Ωë‡Ωî‡ΩÇ‡ºã‡Ωî‡ºã‡Ωë‡ΩÑ‡ºã ‡Ω∫‡Ω¶‡ºã ‡ºã‡Ωë‡Ωî‡ΩÇ‡ºã‡Ωî‡Ω¢‡ºã ‡ºã‡Ωñ‡Ω†‡Ω≤‡ºã‡Ωê‡ºã ‡Ωë‡ºã‡Ωò‡Ω∫‡Ωë‡ºã‡Ωî‡Ω¢‡ºã‡Ω† ‡Ω¢‡ºã‡Ω¢‡Ωº‡ºç ‡ºç ‡Ω†‡Ωë‡Ω≤‡ºã ‡Ω¢‡ºã‡ΩÇ‡Ω£‡ºã‡Ωè‡Ω∫‡ºã‡Ω† ‡ΩÑ‡ºã‡Ωñ‡ºã‡ΩÜ‡Ω∫‡Ωì‡ºã‡Ωî‡Ωº‡ºã‡Ωñ‡Ωû‡Ω≤‡ºã‡Ω£‡Ω¶‡ºã ‡Ω¢‡ºã‡Ωî‡Ω†‡Ω≤‡ºã ‡ºã‡Ω†‡Ωõ‡Ω≤‡Ωì‡ºã‡Ωì‡ºã‡Ωì‡Ω≤‡ºã ‡Ωë‡Ω∫‡ºã‡Ωï‡ºã‡Ω¢‡Ωº‡Ω£‡ºã‡Ωî‡Ωº‡ºã‡Ω£‡ºã‡Ωò‡ºã ‡Ωñ‡ºã‡Ωñ‡Ωº‡ºç ‡ºç ‡Ω†‡Ωº‡Ωì‡ºã‡Ωè‡Ω∫‡ºã‡Ωì‡Ωò‡ºã‡Ωò‡ΩÅ‡Ω†‡Ω≤‡ºã‡Ω°‡Ωº‡Ωì‡ºã‡Ωè‡Ωì‡ºã‡Ω†‡Ωõ‡Ω≤‡Ωì‡ºã ‡Ωì‡ºã‡Ωì‡Ω≤‡ºã‡Ωë‡Ω∫‡ºã‡Ω¢‡ΩÑ‡ºã‡Ωâ‡Ω≤‡Ωë‡ºã‡Ω¶‡ΩÑ‡Ω¶‡ºã ‡Ω¶‡ºã‡Ωî‡ºã‡Ω£‡ºã‡Ωò‡ºã ‡Ωñ‡ºã‡Ωî‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡Ωì‡Ωº‡ºç ‡ºç ‡Ωë‡Ω∫‡ºã ‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã ‡ºã ‡Ω∫‡ºã ‡ΩÇ‡ºã‡Ωî‡ºã ‡ºã‡Ωò‡Ω≤‡ºã ‡ΩÇ‡ºã‡Ωî‡Ω¢‡ºã‡Ωë‡Ωò‡ºã‡Ω†‡ΩÜ‡Ω†‡ºã‡Ωñ‡ºã‡Ωì‡Ω†‡ΩÑ‡ºã ‡Ω¶‡ºã ‡Ωî‡Ω†‡Ω≤‡ºã ‡ºã‡Ω†‡Ωõ‡Ω≤‡Ωì‡ºã‡Ωì‡ºã‡Ωë‡Ω∫‡ºã‡ΩÇ‡Ωû‡Ωì‡ºã‡Ω£‡ºã‡Ωò‡ºã ‡Ωñ‡ºã‡Ωñ‡Ωº‡ºç ‡ºç ‡Ω†‡Ωº‡Ωì‡ºã‡Ωè‡Ω∫‡ºã‡Ωò‡ΩÑ‡Ωº‡Ωì‡ºã‡Ωî‡Ω¢‡ºã ‡ΩÇ‡Ω¶‡Ω£‡ºã‡Ωñ‡Ω¢‡ºã ‡ºã‡Ωñ‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡Ωì‡ºã‡Ωì‡Ω≤‡ºã‡Ωë‡Ω∫‡ºã‡Ω¢‡ΩÑ‡ºã‡Ω£‡ºã‡Ωò‡ºã ‡Ωñ‡ºã‡Ωî‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡Ωì‡Ωº‡ºç ‡ºç ‡Ωë‡Ω∫‡ºã ‡Ωñ‡Ωû‡Ω≤‡Ωì‡ºã ‡ºã‡ΩÖ‡Ω≤‡ºã‡Ω¢‡Ω≤‡ΩÇ‡Ω¶‡ºã‡Ωî‡Ω¢‡ºã‡Ω†‡Ωá‡Ω≤‡ΩÇ‡ºã‡Ωî‡Ω†‡ΩÑ‡ºã‡ΩÇ‡Ω£‡ºã‡Ωè‡Ω∫‡ºã ‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡ΩÖ‡Ω¶‡ºã‡Ωî‡ºã ‡Ω°‡Ω≤‡Ωì‡ºã‡Ωì‡ºã‡Ωì‡Ω≤‡ºã‡Ωë‡Ω∫‡ºã‡Ω¶‡ΩÑ‡Ω¶‡ºã ‡Ω¶‡ºã‡Ωî‡ºã‡Ω¢‡ΩÑ‡ºã‡Ω£‡ºã‡Ωò‡ºã ‡Ωñ‡ºã‡Ωî‡ºã‡Ω°‡Ω≤‡Ωì‡ºã‡Ω£‡ºç ‡Ω†‡Ωº‡Ωì‡ºã‡Ωè‡Ω∫‡ºã ‡ºã Difficult Points in the Opposite of the Consequences, 633.2) identifies the other party as a Dƒ´paka.'*\n",
    "\n",
    ">*'IV.56, sde dge 9a.2: {IV.56} ‡Ωë‡ΩÑ‡Ωº‡Ω¶‡ºã‡Ωî‡Ωº‡ºã‡Ωñ ‡Ωº‡Ωë‡ºã ‡ºã‡Ωò‡Ω∫‡Ωë‡ºã‡Ωî‡ºã‡Ω£‡ºç ‡ºç‡Ωâ‡Ωò‡Ω¶‡ºã‡Ωî‡ºã‡Ωë‡ΩÑ‡ºã‡Ωì‡Ω≤‡ºã‡Ω†‡Ωï‡Ω∫‡Ω£‡ºã‡Ωò‡Ω≤‡ºã ‡ΩÑ‡ºå‡ºç ‡ºç ‡Ωº‡Ωò‡ºã‡Ωû‡Ω∫‡Ω¶‡ºã ‡ºã‡Ωñ‡Ω†‡Ω≤‡ºã‡Ω£‡Ωò‡ºã‡ΩÇ‡æ±‡Ω≤‡Ω¶‡ºã‡Ωì‡Ω≤‡ºç ‡ºç‡ΩÖ‡Ω≤‡ºã‡Ωû‡Ω≤‡ΩÇ‡ºã‡Ωâ‡Ωò‡Ω¶‡ºã‡Ω§‡Ω≤‡ΩÑ‡ºã‡ΩÖ‡Ω≤‡ºã‡Ωû‡Ω≤‡ΩÇ‡ºã‡Ωê‡Ωº‡Ωñ‡ºç ‡ºç 2# Response [to the objection about efficacy] (IV.5758){2 parts} This has two parts: actual response and dispelling an objection to that response.'*\n",
    "\n",
    "3. Others seem to be trivial inclusions either by accident or as seed syllables in an otherwise useful piece of English text like so:\n",
    "\n",
    ">*'THE LIMB OF OFFERING‡æ≤ For this limb visualize incalculable beautiful and captivating offering goddesses who are capable of engendering bliss to both the eyes and the mind of the beholder.'*\n",
    "\n",
    ">*'One day when Hall was having a bath, he began to sing. ‡ºãThe bathroom was small and had a stone floor, so his song was very beautiful, he thought. ‚Äò'*\n",
    "\n",
    "\n",
    "### Test Split\n",
    "\n",
    "There are only five relevant samples in the test split. They are shown below:\n",
    "\n",
    "```\n",
    "{'Source': '‡Ω£‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ωî‡Ω¢‡ºã‡Ωñ‡Ω§‡Ωë‡ºã‡Ωî‡ºã(‡ΩÜ‡Ω¥‡Ω†‡Ω≤‡ºã‡Ωñ‡Ω¶‡æü‡Ωì‡ºã‡Ωñ‡ΩÖ‡Ωº‡Ω¶‡ºã)',\n",
    "  'Target': 'A Treatise on WaterüîΩ ( üîΩ‡Ωë‡Ωº‡Ωì‡ºã‡Ω†‡ΩÇ‡æ±‡Ω¥‡Ω¢‡ºã‡Ωô‡Ωò‡ºã‡Ω¢‡Ω∫‡Ωë‡ºã‡Ω†‡Ωë‡Ω¥‡ΩÇ)',\n",
    "  'File_Name': 'TM4707',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': '‡Ω£‡Ωº‡ºã‡Ωò‡ΩÑ‡ºã‡Ωî‡Ωº‡ºã‡Ωì‡ºã‡Ω£‡Ω¥‡Ω¶‡ºã‡Ωë‡Ω∫‡ºã‡Ωâ‡Ω≤‡Ωë‡ºã‡ΩÄ‡æ±‡Ω≤‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡Ωñ‡æ∑‡Ω≤‡ΩÄ‡æµ‡Ωì‡ºã‡Ωî‡Ω±‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
    "  'Target': '‡ºº‡º¶‡º¢‡ºΩ  After many years, he went in this very body to the realm of the Dakas.üîΩ',\n",
    "  'File_Name': 'TM0770',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': '(‡Ωò‡æ±‡ºã‡ΩÑ‡Ωò‡ºã‡Ωë‡ΩÇ‡Ωº‡Ωì‡ºã‡Ωî‡ºã‡Ω¶‡æ£‡Ωº‡Ωë‡ºã‡Ωñ‡æ±‡Ω¶‡ºã‡Ωì‡Ω¶‡ºã‡Ωê‡Ω¢‡ºã‡Ωñ‡Ω¢‡ºã‡Ωñ‡æ±‡Ω¶‡ºã‡Ωî‡ºã‡Ω£‡Ω¶‡ºã‡ΩÇ‡Ωû‡Ωì‡ºã‡Ωê‡Ωñ‡Ω¶‡ºã‡Ωò‡Ω∫‡Ωë‡ºã‡Ωë‡Ωº‡ºã‡Ω¶‡æô‡Ωò‡ºã‡Ωì‡Ω¶‡ºã‡Ω¶‡æ£‡ºã‡Ω£‡ΩÇ‡ºã‡Ωî‡ºã‡Ωñ‡Ω¶‡æí‡æ≤‡Ω∫‡ΩÑ‡ºã‡Ωñ‡ºã‡Ω£‡æü‡Ω¢‡ºã‡Ωñ‡Ω¢‡æê‡æ±‡ΩÑ‡Ω¶‡ºã‡Ωë‡Ωî‡ΩÇ‡ºã‡Ωö‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡Ωò‡ºã‡Ω°‡Ωº‡Ωë‡ºã‡Ωî‡ºã‡Ω†‡Ωë‡Ω≤‡ºã‡Ω£‡Ω¶‡ºã‡Ωá‡Ω≤‡ºã‡Ω£‡æü‡Ω¢‡ºã‡Ωñ‡Ω¶‡æí‡æ≤‡Ω£‡ºç ‡Ωë‡ºã‡Ωì‡Ω≤‡ºã‡ΩÑ‡Ω†‡Ω≤‡ºã‡Ω§‡ºã‡Ω†‡Ωë‡Ω≤‡ºã‡Ω£‡Ωò‡ºã‡Ω¢‡æí‡æ±‡ΩÇ‡Ω¶‡ºã‡Ωë‡ΩÑ‡ºã‡ºç ‡Ω¢‡æí‡æ±‡Ω¥‡ºã‡Ωò‡Ω†‡Ω≤‡ºã‡ΩÜ‡Ω¥‡ºã‡Ωè‡Ω∫‡ºã‡Ω¶‡æ®‡æ≤‡Ω¶‡ºã‡Ωî‡ºç ) It hardly makes sense, plz check it!',\n",
    "  'Target': '(How can they cross this remote wasteland many leagues across? There is no way for them to escape other than for them to use my flesh as provisions for their journey and to use my entrails as water bags.\"He lifted his trunk to point and told them,) ‡Ωë‡Ωñ‡æ±‡Ω≤‡Ωì‡ºã‡Ωñ‡Ωº‡Ωë‡ºã‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã‡Ωò‡ºã‡Ωë‡Ωî‡Ω∫‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡Ω¶‡æ°‡Ω¥‡Ω¢‡ºã‡Ωì‡Ω¶‡ºã‡Ωñ‡Ω£‡æü‡ºã‡Ωë‡ΩÇ‡Ωº‡Ω¶‡ºã‡Ω†‡Ωë‡Ω¥‡ΩÇ‡ºã‡Ω¶‡æô‡Ωò‡ºç',\n",
    "  'File_Name': 'TM4707',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': '‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ωë‡æ≤‡Ω¥‡ΩÇ‡ºã‡Ωñ‡Ω¢‡æí‡æ±‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡ΩÖ‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡ΩÄ‡Ω≤‡Ω¢‡Ωî‡Ω±‡Ω£‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
    "  'Target': '‡ºº‡ºß‡º§‡ºΩ  With a circle of six hundred, he went to the realm of the Dakas.üîΩ',\n",
    "  'File_Name': 'TM0770',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': '‡Ωò‡Ωê‡Ω¢‡ºã‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ωë‡æ≤‡Ω¥‡ΩÇ‡ºã‡Ωñ‡Ω¢‡æí‡æ±‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡ΩÖ‡Ω¶‡ºã‡Ωì‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡ΩÄ‡Ωî‡Ω±‡Ω£‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
    "  'Target': '‡ºº‡ºß‡º£‡ºΩ  Then, with a circle of six hundred, he went to the realm of the Dakas.üîΩ',\n",
    "  'File_Name': 'TM0770',\n",
    "  'Machine Aligned': True}\n",
    "```\n",
    "\n",
    "Note that in addition to including Tibetan script in the target output, one example also has English in the source text.\n",
    "\n",
    "### Suggestions\n",
    "\n",
    "I suggest the following actions, using the category numbering used in the Train Split section above:\n",
    "\n",
    "For texts of type 1 (Tibetan characters occur as part of an English sentence), I recommend removing these samples from the dataset entirely.\n",
    "\n",
    "For texts of type 2 (Large portion of Tibetan script occur prior to the English), I recommend that these entires be checked by a competent speaker to ensure that the English text is correctly related to the associated source text. If so, the Tibetan script could be manually cleaned.\n",
    "\n",
    "For texts of type 3 (Negligible or small portion of Tibetan script), I recommend that the Tibetan script simply be removed from the target text, with no additional alterations.\n",
    "\n",
    "## Emojis\n",
    "\n",
    "The dataset was then searched for emojis in the target outputs. Again, the train and test sets were both searched. The following code was used:\n",
    "\n",
    "```python\n",
    "emoji_locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for char in texts[i]['Target']:\n",
    "        char_code = ord(char)\n",
    "        if any(start <= char_code <= end for start, end in emoji_ranges):\n",
    "            emoji_locs.append(i)\n",
    "            break\n",
    "```\n",
    "\n",
    "### Train Split\n",
    "\n",
    "There were 0 elements in the Train Split with emojis in the target output. There are also 0 elements with emojis in the source text.\n",
    "\n",
    "### Test Split\n",
    "\n",
    "The test split contains 8436 elements with emojis in the target output. Not all of these include emojis in both the source and target texts. 5593 of them contain the 'Down Arrow' emoji: üîΩ. None of these emojis, at first glance, appear to meaningfully alter the text.\n",
    "\n",
    "### Suggestions\n",
    "\n",
    "I recommend that the emojis simply be removed with no additional alterations to the texts.\n",
    "\n",
    "## Numeric Strings\n",
    "\n",
    "Some elements of the dataset appear to have target outputs that consist only of numerals and punctuation. These are likely to be section headers in the original source.\n",
    "\n",
    "Elements meeting this description were extracted with the following code:\n",
    "\n",
    "```python\n",
    "short_locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    if len(texts[i]['Target'].split(' ')) == 1:\n",
    "                short_locs.append(i)\n",
    "\n",
    "short_texts = [texts[elt] for elt in short_locs]\n",
    "\n",
    "num_range = range(48, 58)\n",
    "num_locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for char in texts[i]['Target']:\n",
    "            if ord(char) in num_range:\n",
    "                num_locs.append(i)\n",
    "                break\n",
    "```\n",
    "\n",
    "### Train Split\n",
    "\n",
    "There are 7571 elements which match this description in the train split. Some samples are shown below:\n",
    "\n",
    "{'Source': '‡ΩÇ‡Ω¶‡Ω¥‡Ωò‡ºã‡Ωî‡ºã‡Ωì‡Ω≤‡ºç',\n",
    " 'Target': '162.',\n",
    " 'File_Name': 'TM1117',\n",
    " 'Machine Aligned': True}\n",
    "\n",
    "{'Source': '‡Ωû‡Ω∫‡Ω¶‡ºã‡Ωî‡Ω¶‡ºã‡Ωñ‡Ω¶‡æü‡Ωì‡ºç',\n",
    " 'Target': '2.2.2.1.1.6.2.3.1.1.2.3.3.2.2.2.1.3.',\n",
    " 'File_Name': 'TM3004',\n",
    " 'Machine Aligned': True}\n",
    "\n",
    "{'Source': '‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã‡Ωî‡ºã‡Ωì‡Ω≤‡ºç',\n",
    " 'Target': '3.2.5.2.1.2.1.2.',\n",
    " 'File_Name': 'TM0581',\n",
    " 'Machine Aligned': True}\n",
    "\n",
    "### Test Split\n",
    "\n",
    "There are only 5 elements which match the description in the test split. They are shown below:\n",
    "\n",
    "```\n",
    "[{'Source': '‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã‡Ωî‡ºã‡Ω£‡ºç',\n",
    "  'Target': '2.',\n",
    "  'File_Name': 'TM0767',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': 'üîΩ',\n",
    "  'Target': '26.üîΩ',\n",
    "  'File_Name': 'TM4793',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': 'üîΩ',\n",
    "  'Target': '25.üîΩ',\n",
    "  'File_Name': 'TM4793',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': '‡Ω¢‡æü‡ΩÇ‡ºã‡Ωî‡ºã‡Ωë‡ΩÑ‡ºã‡ºçüîΩ',\n",
    "  'Target': '3.permanence,üîΩ',\n",
    "  'File_Name': 'TM0757',\n",
    "  'Machine Aligned': True},\n",
    " {'Source': 'üîΩ',\n",
    "  'Target': '29.üîΩ',\n",
    "  'File_Name': 'TM4793',\n",
    "  'Machine Aligned': True}]\n",
    "```\n",
    "\n",
    "These are more clearly problematic than those from train split. Note that 4 of the 5 also include an emoji. More troublingly, 3 of the 5 have only an emoji in the source text but have a numeric string as the target output.\n",
    "\n",
    "### Suggestions\n",
    "\n",
    "The elements in the test split appear irredeemable and should be removed entirely. The elements in the training set may be useful. There are certainly cases in the Tibetan corpus where lengthy numeric strings are used as section headers. It may be valuable for the translation model to be able to handle them effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_locs = []\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    if len(test_texts[i]['Target'].split(' ')) == 1:\n",
    "                short_locs.append(i)\n",
    "\n",
    "short_texts = [test_texts[elt] for elt in short_locs]\n",
    "\n",
    "num_range = range(48, 58)\n",
    "num_locs = []\n",
    "\n",
    "for i in range(len(short_texts)):\n",
    "    for char in short_texts[i]['Target']:\n",
    "            if ord(char) in num_range:\n",
    "                num_locs.append(i)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [short_texts[elt] for elt in num_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Source': '‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã‡Ωî‡ºã‡Ω£‡ºç',\n",
       "  'Target': '2.',\n",
       "  'File_Name': 'TM0767',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': 'üîΩ',\n",
       "  'Target': '26.üîΩ',\n",
       "  'File_Name': 'TM4793',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': 'üîΩ',\n",
       "  'Target': '25.üîΩ',\n",
       "  'File_Name': 'TM4793',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': '‡Ω¢‡æü‡ΩÇ‡ºã‡Ωî‡ºã‡Ωë‡ΩÑ‡ºã‡ºçüîΩ',\n",
       "  'Target': '3.permanence,üîΩ',\n",
       "  'File_Name': 'TM0757',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': 'üîΩ',\n",
       "  'Target': '29.üîΩ',\n",
       "  'File_Name': 'TM4793',\n",
       "  'Machine Aligned': True}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tibetan_range = range(0x0F00, 0x0FFF + 1)\n",
    "locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for char in texts[i]['Target']:\n",
    "            if ord(char) in tibetan_range:\n",
    "                locs.append(i)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2423"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day when Hall was having a bath, he began to sing. ‡ºãThe bathroom was small and had a stone floor, so his song was very beautiful, he thought. ‚Äò'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[locs[6]]['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = load_dataset('openpecha/cleaned_MT_v1.0.2', split=\"test\")\n",
    "\n",
    "test_locs = []\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    for char in test_texts[i]['Target']:\n",
    "            if ord(char) in tibetan_range:\n",
    "                test_locs.append(i)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [test_texts[idx] for idx in test_locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Source': '‡Ω£‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ωî‡Ω¢‡ºã‡Ωñ‡Ω§‡Ωë‡ºã‡Ωî‡ºã(‡ΩÜ‡Ω¥‡Ω†‡Ω≤‡ºã‡Ωñ‡Ω¶‡æü‡Ωì‡ºã‡Ωñ‡ΩÖ‡Ωº‡Ω¶‡ºã)',\n",
       "  'Target': 'A Treatise on WaterüîΩ ( üîΩ‡Ωë‡Ωº‡Ωì‡ºã‡Ω†‡ΩÇ‡æ±‡Ω¥‡Ω¢‡ºã‡Ωô‡Ωò‡ºã‡Ω¢‡Ω∫‡Ωë‡ºã‡Ω†‡Ωë‡Ω¥‡ΩÇ)',\n",
       "  'File_Name': 'TM4707',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': '‡Ω£‡Ωº‡ºã‡Ωò‡ΩÑ‡ºã‡Ωî‡Ωº‡ºã‡Ωì‡ºã‡Ω£‡Ω¥‡Ω¶‡ºã‡Ωë‡Ω∫‡ºã‡Ωâ‡Ω≤‡Ωë‡ºã‡ΩÄ‡æ±‡Ω≤‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡Ωñ‡æ∑‡Ω≤‡ΩÄ‡æµ‡Ωì‡ºã‡Ωî‡Ω±‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
       "  'Target': '‡ºº‡º¶‡º¢‡ºΩ  After many years, he went in this very body to the realm of the Dakas.üîΩ',\n",
       "  'File_Name': 'TM0770',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': '(‡Ωò‡æ±‡ºã‡ΩÑ‡Ωò‡ºã‡Ωë‡ΩÇ‡Ωº‡Ωì‡ºã‡Ωî‡ºã‡Ω¶‡æ£‡Ωº‡Ωë‡ºã‡Ωñ‡æ±‡Ω¶‡ºã‡Ωì‡Ω¶‡ºã‡Ωê‡Ω¢‡ºã‡Ωñ‡Ω¢‡ºã‡Ωñ‡æ±‡Ω¶‡ºã‡Ωî‡ºã‡Ω£‡Ω¶‡ºã‡ΩÇ‡Ωû‡Ωì‡ºã‡Ωê‡Ωñ‡Ω¶‡ºã‡Ωò‡Ω∫‡Ωë‡ºã‡Ωë‡Ωº‡ºã‡Ω¶‡æô‡Ωò‡ºã‡Ωì‡Ω¶‡ºã‡Ω¶‡æ£‡ºã‡Ω£‡ΩÇ‡ºã‡Ωî‡ºã‡Ωñ‡Ω¶‡æí‡æ≤‡Ω∫‡ΩÑ‡ºã‡Ωñ‡ºã‡Ω£‡æü‡Ω¢‡ºã‡Ωñ‡Ω¢‡æê‡æ±‡ΩÑ‡Ω¶‡ºã‡Ωë‡Ωî‡ΩÇ‡ºã‡Ωö‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡Ωò‡ºã‡Ω°‡Ωº‡Ωë‡ºã‡Ωî‡ºã‡Ω†‡Ωë‡Ω≤‡ºã‡Ω£‡Ω¶‡ºã‡Ωá‡Ω≤‡ºã‡Ω£‡æü‡Ω¢‡ºã‡Ωñ‡Ω¶‡æí‡æ≤‡Ω£‡ºç ‡Ωë‡ºã‡Ωì‡Ω≤‡ºã‡ΩÑ‡Ω†‡Ω≤‡ºã‡Ω§‡ºã‡Ω†‡Ωë‡Ω≤‡ºã‡Ω£‡Ωò‡ºã‡Ω¢‡æí‡æ±‡ΩÇ‡Ω¶‡ºã‡Ωë‡ΩÑ‡ºã‡ºç ‡Ω¢‡æí‡æ±‡Ω¥‡ºã‡Ωò‡Ω†‡Ω≤‡ºã‡ΩÜ‡Ω¥‡ºã‡Ωè‡Ω∫‡ºã‡Ω¶‡æ®‡æ≤‡Ω¶‡ºã‡Ωî‡ºç ) It hardly makes sense, plz check it!',\n",
       "  'Target': '(How can they cross this remote wasteland many leagues across? There is no way for them to escape other than for them to use my flesh as provisions for their journey and to use my entrails as water bags.\"He lifted his trunk to point and told them,) ‡Ωë‡Ωñ‡æ±‡Ω≤‡Ωì‡ºã‡Ωñ‡Ωº‡Ωë‡ºã‡ΩÇ‡Ωâ‡Ω≤‡Ω¶‡ºã‡Ωò‡ºã‡Ωë‡Ωî‡Ω∫‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡Ω¶‡æ°‡Ω¥‡Ω¢‡ºã‡Ωì‡Ω¶‡ºã‡Ωñ‡Ω£‡æü‡ºã‡Ωë‡ΩÇ‡Ωº‡Ω¶‡ºã‡Ω†‡Ωë‡Ω¥‡ΩÇ‡ºã‡Ω¶‡æô‡Ωò‡ºç',\n",
       "  'File_Name': 'TM4707',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': '‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ωë‡æ≤‡Ω¥‡ΩÇ‡ºã‡Ωñ‡Ω¢‡æí‡æ±‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡ΩÖ‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡ΩÄ‡Ω≤‡Ω¢‡Ωî‡Ω±‡Ω£‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
       "  'Target': '‡ºº‡ºß‡º§‡ºΩ  With a circle of six hundred, he went to the realm of the Dakas.üîΩ',\n",
       "  'File_Name': 'TM0770',\n",
       "  'Machine Aligned': True},\n",
       " {'Source': '‡Ωò‡Ωê‡Ω¢‡ºã‡Ω†‡ΩÅ‡Ωº‡Ω¢‡ºã‡Ωë‡æ≤‡Ω¥‡ΩÇ‡ºã‡Ωñ‡Ω¢‡æí‡æ±‡ºã‡Ωë‡ΩÑ‡ºã‡Ωñ‡ΩÖ‡Ω¶‡ºã‡Ωì‡Ω¶‡ºã‡Ωò‡ΩÅ‡Ω†‡ºã‡Ω¶‡æ§‡æ±‡Ωº‡Ωë‡ºã‡Ωë‡Ω¥‡ºã‡ΩÇ‡Ω§‡Ω∫‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç ‡ΩÇ‡Ω¥‡Ω¢‡Ω¥‡ΩÄ‡Ωî‡Ω±‡Ω£‡Ω†‡Ω≤‡ºã‡Ω£‡Ωº‡ºã‡Ω¢‡æí‡æ±‡Ω¥‡Ω¶‡ºã‡Ω¢‡æ´‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ω¶‡Ωº‡ºç‡ºç‡ºç‡ºçüîΩ',\n",
       "  'Target': '‡ºº‡ºß‡º£‡ºΩ  Then, with a circle of six hundred, he went to the realm of the Dakas.üîΩ',\n",
       "  'File_Name': 'TM0770',\n",
       "  'Machine Aligned': True}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_ranges = [\n",
    "        (0x1F600, 0x1F64F),  # Emoticons\n",
    "        (0x1F300, 0x1F5FF),  # Miscellaneous Symbols and Pictographs\n",
    "        (0x1F680, 0x1F6FF),  # Transport and Map Symbols\n",
    "        (0x1F700, 0x1F77F),  # Alchemical Symbols\n",
    "        (0x1F780, 0x1F7FF),  # Geometric Shapes Extended\n",
    "        (0x1F900, 0x1F9FF),  # Supplemental Symbols and Pictographs\n",
    "        (0x1FA00, 0x1FA6F)   # Additional Symbols (e.g., Chess)\n",
    "    ]\n",
    "\n",
    "emoji_test_locs = []\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    for char in test_texts[i]['Target']:\n",
    "            char_code = ord(char)\n",
    "            if any(start <= char_code <= end for start, end in emoji_ranges):\n",
    "                emoji_test_locs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_locs = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    for char in texts[i]['Source']:\n",
    "        char_code = ord(char)\n",
    "        if any(start <= char_code <= end for start, end in emoji_ranges):\n",
    "            emoji_locs.append(i)\n",
    "            break\n",
    "\n",
    "len(emoji_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5593"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_locs = []\n",
    "\n",
    "for i in range(len(test_texts)):\n",
    "    for char in test_texts[i]['Target']:\n",
    "        char_code = ord(char)\n",
    "        if char_code == 0x1F53D:\n",
    "            arrow_locs.append(i)\n",
    "            break\n",
    "len(arrow_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8436"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emoji_test_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_arrow_locs = []\n",
    "\n",
    "for elt in emoji_test_locs:\n",
    "    if elt not in arrow_locs:\n",
    "        non_arrow_locs.append(elt)\n",
    "\n",
    "len(non_arrow_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': '‡Ωë‡Ωî‡æ≤‡Ω£‡ºã‡Ωò‡ΩÇ‡æ≤‡Ω≤‡Ωì‡ºã‡Ω¶‡æô‡Ω≤‡ΩÑ‡ºã‡ΩÇ‡Ω¢‡ºã‡Ω®‡Ωº‡Ωæ‡ºã‡Ω®‡Ω±‡Ωø‡ºã‡Ωß‡Ω±‡Ω¥‡æÉ‡ºã‡ΩÇ‡Ω≤‡Ω¶‡ºã‡Ωò‡Ωö‡Ωì‡ºç‡ºç üîΩ‡Ωß‡Ω±‡Ω¥‡Ωæ‡ºã‡Ω£‡Ω¶‡ºã‡Ω†‡Ωº‡Ωë‡ºã‡Ω†‡Ωï‡æ≤‡Ωº‡Ω¶‡ºã‡Ωï‡æ±‡Ωº‡ΩÇ‡Ω¶‡ºã‡Ωñ‡ΩÖ‡Ω¥‡Ω†‡Ω≤‡ºã‡Ω¶‡ΩÑ‡Ω¶‡ºã‡Ω¢‡æí‡æ±‡Ω¶‡ºã‡Ω¢‡æ£‡Ωò‡Ω¶‡ºç‡ºç üîΩ‡ΩÜ‡Ωº‡Ω¶‡ºã‡Ωë‡Ωñ‡æ±‡Ω≤‡ΩÑ‡Ω¶‡ºã‡Ωë‡ΩÇ‡ºã‡Ωî‡Ω†‡Ω≤‡ºã‡ΩÇ‡Ωì‡Ω¶‡ºã‡Ωì‡Ω¶‡ºã‡Ω¶‡æ§‡æ±‡Ωì‡ºã‡Ωë‡æ≤‡ΩÑ‡Ω¶‡ºã‡Ωè‡Ω∫‡ºç‡ºçüîΩ',\n",
       " 'Target': 'Marked by om ah hum in forehead, throat, and heart;üîΩ light rays emanate from hum to the buddhas of ten directionsüîΩ and invoke them from the pure place of the realm of phenomena.üîΩ',\n",
       " 'File_Name': 'TM3076',\n",
       " 'Machine Aligned': True}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[emoji_test_locs[8000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
